# -*- coding: utf-8 -*-
"""hw4_SouradipPal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CfvaokHX3YYlyXDl0n5FRWjhBEj4OWqY
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Purdue/ECE60146/HW4

!wget -O DLStudio-2.2.2.tar.gz \
    https://engineering.purdue.edu/kak/distDLS/DLStudio-2.2.2.tar.gz?download

!tar -xvf DLStudio-2.2.2.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd DLStudio-2.2.2

!pip install pymsgbox

!python setup.py install

# %load_ext autoreload
# %autoreload 2

!pip install pycocotools

import os
import torch
import random
import numpy as np
import requests
import matplotlib.pyplot as plt

from tqdm import tqdm
from PIL import Image
from pycocotools.coco import COCO

seed = 0           
random.seed(seed)
np.random.seed(seed)

from DLStudio import *

!python Examples/playing_with_cifar10.py

!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW4/coco
!wget --no-check-certificate http://images.cocodataset.org/annotations/annotations_trainval2014.zip \
    -O /content/drive/MyDrive/Purdue/ECE60146/HW4/coco/annotations_trainval2014.zip

!unzip /content/drive/MyDrive/Purdue/ECE60146/HW4/coco/annotations_trainval2014.zip -d /content/drive/MyDrive/Purdue/ECE60146/HW4/coco/

!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW4/coco/train2014
!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW4/coco/val2014
!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW4/saved_models

# Image Downloader class to download COCO images
class ImageDownloader():
    def __init__(self, root_dir, annotation_path, classes, imgs_per_class):
        self.root_dir = root_dir
        self.annotation_path = annotation_path
        self.classes = classes
        self.images_per_class = imgs_per_class
        self.class_dir = {}
        self.coco = COCO(self.annotation_path)

    # Create directories same as category names to save images
    def create_dir(self):
        for c in self.classes:
            dir = os.path.join(self.root_dir, c)
            self.class_dir[c] = dir
            if not os.path.exists(dir):
                os.makedirs(dir)

    # Download images
    def download_images(self, download = True, val = False):
        img_paths = {}
        for c in tqdm(self.classes):
            class_id = self.coco.getCatIds(c)
            img_id = self.coco.getImgIds(catIds=class_id)
            imgs = self.coco.loadImgs(img_id)
            img_paths[c] = []

            indices = np.arange(0, self.images_per_class)
            if val == True:
                indices = np.arange(len(imgs) - self.images_per_class, len(imgs))

            for i in indices:
                img_path = os.path.join(self.root_dir, c, imgs[i]['file_name'])
                if download:
                    done = self.download_image(img_path, imgs[i]['coco_url'])
                    if done:
                        self.resize_image(img_path)
                        img_paths[c].append(img_path)
                else:
                    img_paths[c].append(img_path)
            
        return img_paths

    # Download image from URL using requests
    def download_image(self, path, url):
        try:
            img_data = requests.get(url).content
            with open(path, 'wb') as f:
                f.write(img_data)
            return True
        except Exception as e:
            print(f"Caught exception: {e}")
        return False

    # Resize image
    def resize_image(self, path, size = (64, 64)):
        im = Image.open(path)
        if im.mode != "RGB":
            im = im.convert(mode="RGB")
        im_resized = im.resize(size, Image.BOX)
        im_resized.save(path)

classes = ['airplane', 'bus', 'cat', 'dog', 'pizza']
train_imgs_per_class = 1500
val_imgs_per_class = 500

# Download training images
train_downloader = ImageDownloader('/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/train2014', 
                '/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/annotations/instances_train2014.json', 
                classes, train_imgs_per_class)
train_downloader.create_dir()
train_img_paths = train_downloader.download_images(download = False)

# Download validation images
val_downloader = ImageDownloader('/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/val2014', 
                '/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/annotations/instances_train2014.json', 
                classes, val_imgs_per_class)
val_downloader.create_dir()
val_img_paths = val_downloader.download_images(download = False, val = True)

# Plotting sample training images
fig, axes = plt.subplots(5, 3, figsize=(9, 15))

for i, cls in enumerate(classes):
    for j, path in enumerate(train_img_paths[cls][:3]):
        im = Image.open(path)
        axes[i][j].imshow(im)
        axes[i][j].set_title(cls)

fig.suptitle('Sample training images from COCO dataset', fontsize=16, y=0.92)
plt.show()

# Plotting sample validation images
fig, axes = plt.subplots(5, 3, figsize=(9, 15))

for i, cls in enumerate(classes):
    for j, path in enumerate(val_img_paths[cls][:3]):
        im = Image.open(path)
        axes[i][j].imshow(im)
        axes[i][j].set_title(cls)

fig.suptitle('Sample validation images from COCO dataset', fontsize=16, y=0.92)
plt.show()

import os
import torch

# Custom dataset class for COCO
class CocoDataset(torch.utils.data.Dataset):
    def __init__(self, root, transforms=None):
        super().__init__()
        self.root_dir = root
        self.classes = os.listdir(self.root_dir)
        self.transforms = transforms
        self.img_paths = []
        self.img_labels = []
        self.class_to_idx = {'airplane':0, 'bus':1, 'cat':2, 'dog':3, 'pizza': 4}
        self.idx_to_class = {i:c for c, i in self.class_to_idx.items()}

        for cls in self.classes:
            cls_dir = os.path.join(self.root_dir, cls)
            paths = os.listdir(cls_dir)
            self.img_paths+= [os.path.join(cls_dir, path) for path in paths]
            self.img_labels+=[self.class_to_idx[cls]]*len(paths)

    def __len__(self):
        # Return the total number of images
        return len(self.img_paths)

    def __getitem__(self, index):
        index = index % len(self.img_paths)
        img_path = self.img_paths[index]
        img_label = self.img_labels[index]
        img = Image.open(img_path)
        img_transformed = self.transforms(img)
        return img_transformed, img_label

import torchvision.transforms as tvt

reshape_size = 64
transforms = tvt.Compose([
    tvt.ToTensor(),
    tvt.Resize((reshape_size, reshape_size)),
    tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

# Create custom training dataset
train_dataset = CocoDataset('/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/train2014/', transforms=transforms)

len(train_dataset)

# Create custom validation dataset
val_dataset = CocoDataset('/content/drive/MyDrive/Purdue/ECE60146/HW4/coco/val2014/', transforms=transforms)

len(val_dataset)

# Create custom training/validation dataloader
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)

# Check dataloader
train_loader_iter = iter(train_data_loader)
img, target = next(train_loader_iter)

print('img has length: ', len(img))
print('target has length: ', len(target))
print(img[0].shape)

# Routin to train a neural network classifier
def train_net(device, net, optimizer, criterion, data_loader, model_name,
              epochs = 10, display_interval = 100):
    net = net.to(device)
    loss_running_record = []

    for epoch in range(epochs):
        running_loss = 0.0
        for i, data in enumerate(data_loader):
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if (i+1) % display_interval == 0:
                avg_loss = running_loss / display_interval
                print ("[epoch : %d, batch : %5d] loss : %.3f" % (epoch + 1, i + 1, avg_loss))
                loss_running_record.append(avg_loss)
            running_loss = 0.0
    
    checkpoint_path = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW4/saved_models', 
                                   f'{model_name}.pth')
    torch.save(net.state_dict(), checkpoint_path)

    return loss_running_record

# Plotting training loss
def plot_loss(loss, display_interval, model_name):
    plt.figure()
    plt.plot(np.arange(len(loss))*display_interval, loss);
    plt.title(f'Training Loss for {model_name}')
    plt.xlabel('Iterations')
    plt.ylabel('Loss') 
    plt.show()

# Routine to validate a neural network classifier
def validate_net(device, net, data_loader, model_path = None):
    if model_path is not None:
        net.load_state_dict(torch.load(model_path))
    net = net.to(device)
    net.eval()
    running_loss = 0.0

    device_cpu = torch.device('cpu')

    iters = 0
    imgs = []
    all_labels = []
    all_pred = []
    
    with torch.no_grad():
        for i, data in enumerate(data_loader):
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss
            iters += 1
            pred_labels = torch.argmax(outputs.data, axis = 1)
            all_labels += list(labels.to(device_cpu).numpy())
            all_pred += list(pred_labels.to(device_cpu).numpy())
            imgs += list(inputs.to(device_cpu))

        print(f"Validation Loss: {running_loss/iters}")
        
    return imgs, all_labels, all_pred

# Function to calculate confusion matrix
def calc_confusion_matrix(num_classes, actual, predicted):
    conf_mat = np.zeros((num_classes, num_classes))
    for a, p in zip(actual, predicted):
        conf_mat[a][p]+=1
    return conf_mat

import seaborn as sns

# Plotting confusion matrix
def plot_conf_mat(conf_mat, classes, model_name):
    labels = []
    num_classes = len(classes)
    labels_per_class =  np.sum(conf_mat) / num_classes
    for row in range(num_classes):
        rows = []
        for col in range(num_classes):
            count = conf_mat[row][col]
            percent = "%.2f%%" % (count / labels_per_class * 100)
            label = str(count) + '\n' + str(percent)
            rows.append(label)
        labels.append(rows)
    labels = np.asarray(labels)
    
    plt.figure(figsize=(6, 6))
    sns.heatmap(conf_mat, annot=labels, fmt="", cmap="YlOrBr", cbar=True, 
                xticklabels=classes, yticklabels=classes)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.title(f'Confusion Matrix for model {model_name}')
    plt.show()

# Define Net1 architecture
import torch.nn as nn
import torch.nn.functional as F

class HW4Net(nn.Module):
    def __init__(self):
        super(HW4Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d (16, 32, 3)
        self.fc1 = nn.Linear(6272, 64)
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# Initialize Net1
net = HW4Net()
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters() , lr=1e-3, betas=(0.9, 0.999))
epochs = 20
display_interval = 5

# Train Net1
net1_losses = train_net(device, net, optimizer=optimizer, criterion=criterion, 
                        data_loader = train_data_loader, model_name = 'net1', 
                        epochs=epochs, display_interval = display_interval)

# Plotting Net1 training loss
plot_loss(net1_losses, display_interval, 'Net1')

# Validate Net1
save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW4/saved_models/net1.pth'
imgs, actual, predicted = validate_net(device, net, val_data_loader, model_path = save_path)

# Calculate Net1 confusion matrix and accuracy
conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy = np.trace(conf_mat) / float(np.sum(conf_mat))
print(accuracy)

# Plotting Net1 confusion matrix
plot_conf_mat(conf_mat, classes, 'Net1')

# Define Net2
class Net2(nn.Module):
    def __init__(self):
        super(Net2, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)
        self.fc1 = nn.Linear(8192, 64)
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize Net2
net2 = Net2()
net2 = net2.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net2.parameters() , lr=1e-3, betas=(0.9, 0.999))
epochs = 20
display_interval = 5

# Train Net1
net2_losses = train_net(device, net2, optimizer=optimizer, criterion=criterion, 
                        data_loader = train_data_loader, model_name = 'net2', 
                        epochs=epochs, display_interval = display_interval)

# Plotting Net2 training loss
plot_loss(net2_losses, display_interval, 'Net2')

save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW4/saved_models/net2.pth'
imgs, actual, predicted = validate_net(device, net2, val_data_loader, model_path = save_path)

conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy = np.trace(conf_mat) / float(np.sum(conf_mat))
print(accuracy)

plot_conf_mat(conf_mat, classes, 'Net2')

class Net3(nn.Module):
    def __init__(self):
        super(Net3, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 3)
        self.conv3 = nn.Conv2d(32, 32, 3, padding = 1)
        self.fc1 = nn.Linear(6272, 64)
        self.fc2 = nn.Linear(64, 5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        for i in range(10):
            x = F.relu(self.conv3(x))
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

net3 = Net3()
net3 = net3.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net3.parameters() , lr=1e-3, betas=(0.9, 0.999))
epochs = 20
display_interval = 5

net3_losses = train_net(device, net3, optimizer=optimizer, criterion=criterion, 
                        data_loader = train_data_loader, model_name = 'net3', 
                        epochs=epochs, display_interval = display_interval)

plot_loss(net3_losses, display_interval, 'Net3')

save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW4/saved_models/net3.pth'
imgs, actual, predicted = validate_net(device, net3, val_data_loader, model_path = save_path)

conf_mat = calc_confusion_matrix(5, actual, predicted)
print(conf_mat)
accuracy = np.trace(conf_mat) / float(np.sum(conf_mat))
print(accuracy)

plot_conf_mat(conf_mat, classes, 'Net3')

# Plotting training loss for Net1, Net2 and Net3
plt.figure()
x = np.arange(len(net1_losses))*display_interval
plt.plot(x, net1_losses, label='Net1')
plt.plot(x, net2_losses, label='Net2')
plt.plot(x, net3_losses, label='Net3')
plt.title('Training CNN Classifiers')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.legend() 
plt.show()

