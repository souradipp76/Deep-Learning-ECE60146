# -*- coding: utf-8 -*-
"""hw7_SouradipPal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V-aEyQyL4ry1kcADf4lvxBAmta7uM_8y
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Purdue/ECE60146/

!wget -O DLStudio-2.2.5.tar.gz \
    https://engineering.purdue.edu/kak/distDLS/DLStudio-2.2.5.tar.gz?download

!tar -xvf DLStudio-2.2.5.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Purdue/ECE60146/DLStudio-2.2.5/

!pip install pymsgbox

!python setup.py install

# %load_ext autoreload
# %autoreload 2

import os
import torch
import random
import numpy as np
import requests
import matplotlib.pyplot as plt

from tqdm import tqdm
from PIL import Image

seed = 0           
random.seed(seed)
np.random.seed(seed)

from DLStudio import *

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Purdue/ECE60146/DLStudio-2.2.5/ExamplesAdversarialLearning/

!wget -O /content/datasets_for_AdversarialNetworks.tar.gz \
    https://engineering.purdue.edu/kak/distDLS/datasets_for_AdversarialNetworks.tar.gz

!tar -xvf /content/datasets_for_AdversarialNetworks.tar.gz -C \
    /content/drive/MyDrive/Purdue/ECE60146/DLStudio-2.2.5/ExamplesAdversarialLearning/dataGAN

!tar -xvf ./dataGAN/PurdueShapes5GAN-20000.tar.gz -C ./dataGAN/

!python dcgan_DG1.py

!python wgan_CG1.py

!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW7/data/
!mkdir /content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models

!unzip /content/pizzas.zip -d /content/drive/MyDrive/Purdue/ECE60146/HW7/data/

# Plotting sample training images
fig, axes = plt.subplots(3, 3, figsize=(9, 9))

root = '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/train/'
img_paths = os.listdir(root)
for i in range(3):
    for j in range(3):
        path = img_paths[3*i+j]
        im = Image.open(os.path.join(root, path)).convert('RGB')
        im = np.ascontiguousarray(im, dtype=np.uint8)
        axes[i][j].imshow(im)

fig.suptitle('Sample training images from PIZZA dataset', fontsize=16, y=0.95)
plt.show()

# Plotting sample validation images
fig, axes = plt.subplots(3, 3, figsize=(9, 9))

root = '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/eval/'
img_paths = os.listdir(root)
for i in range(3):
    for j in range(3):
        path = img_paths[3*i+j]
        im = Image.open(os.path.join(root, path)).convert('RGB')
        im = np.ascontiguousarray(im, dtype=np.uint8)
        axes[i][j].imshow(im)

fig.suptitle('Sample validation images from PIZZA dataset', fontsize=16, y=0.95)
plt.show()

import os
import torch

# Custom dataset class for Pizza GAN
class PizzaDataset(torch.utils.data.Dataset):
    def __init__(self, root, transforms=None, mode = 'train'):
        super().__init__()
        self.mode = mode
        self.root_dir = root
        self.img_paths = os.listdir(self.root_dir)
        self.transforms = transforms

    def __len__(self):
        # Return the total number of images
        return len(self.img_paths)

    def __getitem__(self, index):
        index = index % len(self.img_paths)
        img_path = self.img_paths[index]
        im = Image.open(os.path.join(self.root_dir, img_path)).convert('RGB')
        im_transformed = self.transforms(im)
        
        return im_transformed

import torchvision.transforms as tvt

reshape_size = 64
transforms = tvt.Compose([
    tvt.ToTensor(),
    tvt.Resize((reshape_size, reshape_size), antialias=True),
    tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

# Create custom training dataset
train_dataset = PizzaDataset('/content/drive/MyDrive/Purdue/ECE60146/HW7/data/train/', transforms=transforms)

len(train_dataset)

# Create custom validation dataset
val_dataset = PizzaDataset('/content/drive/MyDrive/Purdue/ECE60146/HW7/data/eval/', transforms=transforms, mode = 'test')

len(val_dataset)

# Create custom training/validation dataloader
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)

# Check dataloader
train_loader_iter = iter(train_data_loader)
img = next(train_loader_iter)

print('img has length: ', len(img))
#print('target has length: ', len(label))
print(img[0].shape)

# Method to initialize Conv and BatchNorm weights
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

import torch.nn as nn
import torch.optim as optim
import torchvision
import imageio 

# Routine to train a DCGAN
def train_gan(device, generator, discriminator, data_loader, model_name, 
              dir_name_for_results = None, epochs = 10, display_interval = 100):
    
    batch_size = 64
    nz = 100
    netD = discriminator.to(device)
    netG = generator.to(device)

    fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)          
    real_label = 1   
    fake_label = 0

    # Adam optimizers for the Discriminator and the Generator:
    optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))    
    optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    # Loss
    criterion = nn.BCELoss()

    img_list = []                               
    G_losses = []                               
    D_losses = [] 
    mean_D_losses = []
    mean_G_losses = []
                              
    iters = 0                                   
    print("\n\nStarting Training Loop...\n\n")                
    for epoch in range(epochs):        
        g_losses_per_print_cycle = []           
        d_losses_per_print_cycle = []           
        # For each batch in the dataloader
        for i, data in enumerate(data_loader, 0):  
            # Training Discriminator with Real Images    
            netD.zero_grad()    
            real_images_in_batch = data.to(device)     
            b_size = real_images_in_batch.size(0)  
            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)  
            output = netD(real_images_in_batch).view(-1)  
            lossD_for_reals = criterion(output, label)                                                   
            lossD_for_reals.backward()                                                                   
    
            # Training Discriminator with Fake Images
            noise = torch.randn(b_size, nz, 1, 1, device=device)    
            fakes = netG(noise) 
            label.fill_(fake_label) 
            output = netD(fakes.detach()).view(-1)  
            lossD_for_fakes = criterion(output, label) 
            lossD_for_fakes.backward() 

            lossD = lossD_for_reals + lossD_for_fakes    
            d_losses_per_print_cycle.append(lossD)

            # Update Discriminator
            optimizerD.step()  
    
            # Training Generator
            netG.zero_grad()   
            label.fill_(real_label)  
            output = netD(fakes).view(-1)   
            lossG = criterion(output, label)          
            g_losses_per_print_cycle.append(lossG) 
            lossG.backward()    
            optimizerG.step() 
            
            if (i+1) % display_interval == 0:
                mean_D_loss = torch.mean(torch.FloatTensor(d_losses_per_print_cycle))
                mean_G_loss = torch.mean(torch.FloatTensor(g_losses_per_print_cycle))
                mean_D_losses.append(mean_D_loss.item())
                mean_G_losses.append(mean_G_loss.item())
                print("[epoch=%d/%d iter=%4d] mean_D_loss=%7.4f mean_G_loss=%7.4f" %
                    ((epoch+1),epochs,(i+1), mean_D_loss, mean_G_loss))
                d_losses_per_print_cycle = []
                g_losses_per_print_cycle = []
                
            G_losses.append(lossG.item())
            D_losses.append(lossD.item())
            
            if (i == len(data_loader)-1):
                with torch.no_grad():
                    fake = netG(fixed_noise).detach().cpu()
                img_list.append(torchvision.utils.make_grid(fake, padding=1, pad_value=1, normalize=True))
            iters += 1
    
    # At the end of training, make plots from the data in G_losses and D_losses:
    fig,axes = plt.subplots(1,2,figsize= (12,6))
    axes[0].plot(mean_G_losses)
    axes[0].set_xlabel("iterations") 
    axes[0].set_ylabel("Loss")
    axes[0].set_title("Mean Generator Loss During Training")
    axes[1].plot(mean_D_losses)
    axes[1].set_title("Mean Discriminator Loss During Training")
    axes[1].set_xlabel("iterations")
    axes[1].set_ylabel("Loss")
    plt.savefig(dir_name_for_results + "gen_and_disc_loss_training.png")
    plt.show()

    plt.figure(figsize=(10,5))                                                                             
    plt.title("Generator and Discriminator Loss During Training")                                          
    plt.plot(mean_G_losses,label="G")                                                                           
    plt.plot(mean_D_losses,label="D")                                                                           
    plt.xlabel("iterations")                                                                               
    plt.ylabel("Loss")                                                                                     
    plt.legend()                                                                                           
    plt.savefig(dir_name_for_results + "gen_and_disc_loss_training2.png")                                  
    plt.show() 

    # Comparison of Real and Fake Images
    real_batch = next(iter(data_loader))
    plt.figure(figsize=(8,8))
    plt.axis("off")
    plt.title("Real Images")
    r_imgs = np.transpose(torchvision.utils.make_grid(real_batch.to(device), \
                            padding=1, pad_value=1, normalize=True).cpu(),(1,2,0))
    plt.imshow(r_imgs)
    plt.savefig(dir_name_for_results + 'Real_Images.jpg')
    plt.show()

    plt.figure(figsize=(8,8))
    plt.axis("off")
    plt.title("Fake Images")
    plt.imshow(np.transpose(img_list[-1],(1,2,0)))
    plt.savefig(dir_name_for_results + 'Fake_Images.jpg')
    plt.show()

    images = []           
    for imgobj in img_list:  
        img = tvt.ToPILImage()(imgobj)  
        images.append(img) 
    imageio.mimsave(dir_name_for_results + "generation_animation.gif", images, fps=5)

    # Save model weights
    checkpoint_path_G = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                                   f'{model_name}_G.pt')
    torch.save(netG.state_dict(), checkpoint_path_G)
    checkpoint_path_D = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                                   f'{model_name}_D.pt')
    torch.save(netD.state_dict(), checkpoint_path_D)

    return mean_D_losses, mean_G_losses, img_list

# Plotting training loss
def plot_loss(mean_D_losses, mean_G_losses, display_interval, model_name):
    plt.figure()
    plt.plot(np.arange(len(mean_D_losses))*display_interval, mean_D_losses, label="Discriminator Loss");
    plt.plot(np.arange(len(mean_G_losses))*display_interval, mean_G_losses, label="Generator Loss");
    plt.title(f'Training Loss for {model_name}')
    plt.xlabel('Iterations')
    plt.ylabel('Loss') 
    plt.legend()
    plt.show()

!pip install pytorch-fid

# Routine to validate GAN
from pytorch_fid.fid_score import calculate_activation_statistics, calculate_frechet_distance
from pytorch_fid.inception import InceptionV3

def validate_gan(device, netG, real_root_dir, fake_root_dir, model_name = None, model_path = None):
    if model_path is not None:
        netG.load_state_dict(torch.load(model_path))
    netG = netG.to(device)
    netG.eval()

    nz = 100
    noise = torch.randn(1000, nz, 1, 1, device=device)
    img_paths = []

    invTrans = tvt.Compose([ tvt.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.5, 1/0.5, 1/0.5 ]),
                                tvt.Normalize(mean = [ -0.5, -0.5, -0.5 ], std = [ 1., 1., 1. ]),
                            ])
    # generate fake images
    with torch.no_grad():     
        fakes = netG(noise)
        for i in range(noise.shape[0]):
            img = invTrans(fakes[i])
            img = tvt.ToPILImage()(img)
            im_path = os.path.join(fake_root_dir, f"gen_{i:03d}.jpeg")
            img.save(im_path)
            img_paths.append(im_path)

    # calculate FID score
    real_img_paths = os.listdir(real_root_dir)
    fake_img_paths = os.listdir(fake_root_dir)
    real_paths = [os.path.join(real_root_dir, path) for path in real_img_paths]
    fake_paths = [os.path.join(fake_root_dir, path) for path in fake_img_paths]
    dims = 2048
    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]
    model = InceptionV3([block_idx]).to(device)
    m1, s1 = calculate_activation_statistics(real_paths, model, device = device)
    m2, s2 = calculate_activation_statistics(fake_paths, model, device = device)
    fid_value = calculate_frechet_distance(m1, s1, m2, s2)
    print(f'FID: {fid_value:.2f}')

    # Plotting sample generated images
    fig, axes = plt.subplots(4, 4, figsize=(12, 12))
    for i in range(4):
        for j in range(4):
            path = img_paths[4*i+j]
            im = Image.open(os.path.join(root, path)).convert('RGB')
            im = np.ascontiguousarray(im, dtype=np.uint8)
            axes[i][j].imshow(im)

    fig.suptitle(f'Generated images using {model_name}', fontsize=16, y=0.95)
    plt.show()

# DCGAN Generator
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.model = nn.Sequential(
            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),
            nn.BatchNorm2d(64 * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()
            )
    
    def forward(self, input):
        return self.model(input)

# DCGAN Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, 4, 2, 1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
            )
            
    def forward(self, input):
        return self.model(input)

# Initialize device
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
device

# Initialize DCGAN
netD = Discriminator()
netG = Generator()

netD.apply(weights_init)
netG.apply(weights_init)

# netG.load_state_dict(torch.load('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_BCE_2_G.pt'))
# netD.load_state_dict(torch.load('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_BCE_2_D.pt'))

epochs = 50
display_interval = 5

num_learnable_params_disc = sum(p.numel() for p in netD.parameters() if p.requires_grad)
print("\n\nThe number of learnable parameters in the Discriminator: %d\n" % num_learnable_params_disc)
num_learnable_params_gen = sum(p.numel() for p in netG.parameters() if p.requires_grad)
print("\nThe number of learnable parameters in the Generator: %d\n" % num_learnable_params_gen)
num_layers_disc = len(list(netD.parameters()))
print("\nThe number of layers in the Discriminator: %d\n" % num_layers_disc)
num_layers_gen = len(list(netG.parameters()))
print("\nThe number of layers in the Generator: %d\n\n" % num_layers_gen)

# Train DCGAN with BCE Loss
net1_losses = train_gan(device, netG, netD, data_loader = train_data_loader, 
                        model_name = 'HW7_BCE_3', dir_name_for_results =
                         '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/bce_gan/',
                        epochs=epochs, display_interval = display_interval)

# Validate DCGAN with BCE Loss
save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_BCE_3_G.pt'
validate_gan(device, netG,'/content/drive/MyDrive/Purdue/ECE60146/HW7/data/eval', \
                '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/bce_gan/images', 
             model_name = 'DCGAN_BCELoss', model_path = save_path)

# Skip Block for WGAN
class SkipBlock(nn.Module):
    def __init__(self, in_ch, out_ch, downsample=False, skip_connections=True):
        super(SkipBlock, self).__init__()
        self.downsample = downsample
        self.skip_connections = skip_connections
        self.in_ch = in_ch
        self.out_ch = out_ch
        self.convo1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1)
        self.convo2 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(out_ch)
        self.bn2 = nn.BatchNorm2d(out_ch)
        self.downsampler1 = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=2)
        self.downsampler2 = nn.Conv2d(out_ch, out_ch, kernel_size=1, stride=2)
        self.leaky_relu = nn.LeakyReLU(0.2)
    
    def forward(self, x):
        identity = x                                     
        out = self.convo1(x)                              
        out = self.bn1(out)                              
        out = torch.nn.functional.relu(out)
        if self.in_ch == self.out_ch:
            out = self.convo2(out)                              
            out = self.bn2(out)                              
            out = self.leaky_relu(out)
        if self.downsample:
            out = self.downsampler2(out)
            identity = self.downsampler1(identity)
        if self.skip_connections:
            out += identity                              
        return out

# Critic for WGAN
class CriticCG(nn.Module):
    def __init__(self):
        super(CriticCG, self).__init__()
        self.conv_in = SkipBlock(3, 64, downsample=True, skip_connections=True)
        self.conv_in2 = SkipBlock(64, 128, downsample=True, skip_connections=False)
        self.conv_in3 = SkipBlock(128, 256, downsample=True, skip_connections=False)
        self.conv_in4 = SkipBlock(256, 512, downsample=True, skip_connections=False)
        self.bn1 = nn.BatchNorm2d(128)
        self.bn2 = nn.BatchNorm2d(256)
        self.bn3 = nn.BatchNorm2d(512)
        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)
        self.final = nn.Linear(512*4*4, 1)
    
    def forward(self, x):              
        x = self.leaky_relu(self.conv_in(x))
        x = self.bn1(self.conv_in2(x))
        x = self.leaky_relu(x)
        x = self.bn2(self.conv_in3(x))
        x = self.leaky_relu(x)
        x = self.bn3(self.conv_in4(x))
        x = self.leaky_relu(x)
        x = x.flatten(1)
        x = self.final(x)
        x = x.mean(0)     
        x = x.view(1)
        return x

# Generator for WGAN
class GeneratorCG(nn.Module):
    def __init__(self):
        super(GeneratorCG, self).__init__()
        self.latent_to_image = nn.ConvTranspose2d(100, 512, kernel_size=4, stride=1, padding=0, bias=False)
        self.upsampler2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False)
        self.upsampler3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False)
        self.upsampler4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)
        self.upsampler5 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(512)
        self.bn2 = nn.BatchNorm2d(256)
        self.bn3 = nn.BatchNorm2d(128)
        self.bn4 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.tanh  = nn.Tanh()
    
    def forward(self, x):                   
        x = self.latent_to_image(x)
        x = self.relu(self.bn1(x))
        x = self.upsampler2(x)
        x = self.relu(self.bn2(x))
        x = self.upsampler3(x)
        x = self.relu(self.bn3(x))
        x = self.upsampler4(x)
        x = self.relu(self.bn4(x))
        x = self.upsampler5(x)
        x = self.tanh(x)
        return x

# Initialize WGAN
netC = CriticCG()
netG = GeneratorCG()

netC.apply(weights_init)
netG.apply(weights_init)

# netG.load_state_dict(torch.load('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_WGAN_2_G.pt'))
# netC.load_state_dict(torch.load('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_WGAN_2_C.pt'))

epochs = 100
display_interval = 20

num_learnable_params_critic = sum(p.numel() for p in netC.parameters() if p.requires_grad)
print("\n\nThe number of learnable parameters in the Critic: %d\n" % num_learnable_params_critic)
num_learnable_params_gen = sum(p.numel() for p in netG.parameters() if p.requires_grad)
print("\nThe number of learnable parameters in the Generator: %d\n" % num_learnable_params_gen)
num_layers_critic = len(list(netC.parameters()))
print("\nThe number of layers in the Critic: %d\n" % num_layers_critic)
num_layers_gen = len(list(netG.parameters()))
print("\nThe number of layers in the Generator: %d\n\n" % num_layers_gen)

# Routine to train a WGAN
def train_wgan(device, critic, generator, data_loader, model_name, 
               dir_name_for_results, epochs = 10, display_interval = 100):
    
    nz = 100

    netC = critic.to(device)
    netG = generator.to(device)

    batch_size = 64

    fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)

    one = torch.FloatTensor([1]).to(device)
    minus_one = torch.FloatTensor([-1]).to(device)

    #  Adam optimizers for the Critic and the Generator:
    optimizerC = optim.Adam(netC.parameters(), lr=0.0002, betas=(0.5, 0.999))    
    optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    img_list = []                               
    Gen_losses = []                               
    Cri_losses = []

    iters = 0                                   
    gen_iterations = 0
    print("\n\nStarting Training Loop.......\n\n")          
    clipping_thresh = 0.005
    # For each epoch
    for epoch in range(epochs):       
        data_iter = iter(data_loader)
        i = 0
        ncritic = 5
        while i < len(data_loader):
            for p in netC.parameters():
                p.requires_grad = True          
            if gen_iterations < 25 or gen_iterations % display_interval == 0: 
                ncritic = 100
            ic = 0
            while ic < ncritic and i < len(data_loader):
                ic += 1
                for p in netC.parameters():
                    p.data.clamp_(-clipping_thresh, clipping_thresh)

                ## Training the Critic with real images
                netC.zero_grad()                                                                            
                real_images_in_batch = next(data_iter)
                i += 1
                real_images_in_batch = real_images_in_batch.to(device)   
                b_size = real_images_in_batch.size(0)   
                critic_for_reals_mean = netC(real_images_in_batch)
                critic_for_reals_mean.backward(minus_one)  

                ## Training the Critic with fake images
                noise = torch.randn(b_size, nz, 1, 1, device=device)    
                fakes = netG(noise)          
                critic_for_fakes_mean = netC(fakes)
                critic_for_fakes_mean.backward(one)
                wasser_dist = critic_for_reals_mean - critic_for_fakes_mean
                loss_critic = critic_for_fakes_mean - critic_for_reals_mean
                
                #  Update the Critic
                optimizerC.step()   

            ## Training the Generator
            for p in netC.parameters():
                p.requires_grad = False
            netG.zero_grad()

            noise = torch.randn(b_size, nz, 1, 1, device=device)    
            fakes = netG(noise)          
            critic_for_fakes_mean = netC(fakes)
            loss_gen = critic_for_fakes_mean
            critic_for_fakes_mean.backward(minus_one)                       
            
            #  Update the Generator
            optimizerG.step()                                                                          
            gen_iterations += 1
            if i % (ncritic) == 0:                                                   
                print("[epoch=%d/%d   i=%4d]     loss_critic=%7.4f   loss_gen=%7.4f   Wasserstein_dist=%7.4f" %  \
                        (epoch,epochs,i,loss_critic.data[0], loss_gen.data[0], wasser_dist.data[0]))

            Gen_losses.append(loss_gen.data[0].item())      
            Cri_losses.append(loss_critic.data[0].item())   
            
            if (iters % display_interval == 0) or ((epoch == epochs-1) and (i == len(data_loader)-1)): 
                with torch.no_grad():                                                                        
                    fake = netG(fixed_noise).detach().cpu()  
                img_list.append(torchvision.utils.make_grid(fake, padding=1, pad_value=1, normalize=True))   
            iters += 1                                                                                        
    
    #  At the end of training, make plots from the data in Gen_losses and Cri_losses:
    plt.figure(figsize=(10,5))                                                                             
    plt.title("Generator and Critic Loss During Training")                                          
    plt.plot(Gen_losses,label="G")                                                                           
    plt.plot(Cri_losses,label="C")                                                                           
    plt.xlabel("iterations")                                                                               
    plt.ylabel("Loss")                                                                                     
    plt.legend()                                                                                           
    plt.savefig(dir_name_for_results + "gen_and_critic_loss_training.png")                                  
    plt.show()                                                                                             
    
    #  Create GIF            
    images = []                                                                                            
    for imgobj in img_list:                                                                                
        img = tvt.ToPILImage()(imgobj)                                                                    
        images.append(img)                                                                                 
    imageio.mimsave(dir_name_for_results + "generation_animation.gif", images, fps=5)                     
    
    # Compare Real and Fake Images
    real_batch = next(iter(data_loader))                                                        
    real_batch = real_batch
    plt.figure(figsize=(15,15))                                                                           
    plt.subplot(1,2,1)                                                                                    
    plt.axis("off")                                                                                       
    plt.title("Real Images")                                                                              
    plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch.to(device), 
                                        padding=1, pad_value=1, normalize=True).cpu(),(1,2,0)))  
    plt.subplot(1,2,2)                                                                             
    plt.axis("off")                                                                                
    plt.title("Fake Images")                                                                       
    plt.imshow(np.transpose(img_list[-1],(1,2,0)))                                                 
    plt.savefig(dir_name_for_results + "real_vs_fake_images.png")                                 
    plt.show()

    # Save model weights
    checkpoint_path_G = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                        f'{model_name}_G.pt')
    torch.save(netG.state_dict(), checkpoint_path_G)
    checkpoint_path_C = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                                f'{model_name}_C.pt')
    torch.save(netC.state_dict(), checkpoint_path_C) 

    return Cri_losses, Gen_losses, img_list

# Training WGAN
net2_losses = train_wgan(device, netC, netG, data_loader = train_data_loader, 
                        model_name = 'HW7_WGAN', dir_name_for_results =
                         '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/wgan', 
                        epochs=epochs, display_interval = display_interval)

# Validate WGAN
save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_WGAN_G.pt'
validate_gan(device, netG,'/content/drive/MyDrive/Purdue/ECE60146/HW7/data/eval', \
                '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/wgan/images', 
             model_name = 'WGAN', model_path = save_path)

# Different Routine to train a WGAN
def train_wgan_2(device, critic, generator, data_loader, model_name, 
               dir_name_for_results, epochs = 10, display_interval = 100):
    
    nz = 100

    netC = critic.to(device)
    netG = generator.to(device)

    batch_size = 64

    fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)

    #  Adam optimizers for the Critic and the Generator:
    optimizerC = optim.Adam(netC.parameters(), lr=0.0002, betas=(0.5, 0.999))    
    optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    img_list = []                               
    Gen_losses = []                               
    Cri_losses = []
    
    ncritic = 5
    iters = 0                                   
    gen_iterations = 0
    print("\n\nStarting Training Loop.......\n\n")          
    clipping_thresh = 0.02
    # For each epoch
    for epoch in range(epochs):

        for i, data in enumerate(data_loader):
            b_size = data.shape[0]
            data = data.to(device)
            
            z = torch.randn(b_size, nz, 1, 1).to(device)
            fake = netG(z)

            #Train critic function
            for p in netC.parameters():
                p.requires_grad = True
            netC.zero_grad()
            real_critic = fwx = netC(data)
            fake_critic = fwg = netC(fake.detach())

            loss_fw = fwg - fwx
            loss_fw.backward()
            optimizerC.step()

            #weight clipping
            for p in netC.parameters():
                p.data.clamp_(-clipping_thresh, clipping_thresh)
            
            #Train G
            if (i+1) % ncritic==0:
                for p in netC.parameters():
                    p.requires_grad = False
                netG.zero_grad()
                fake = netG(z)
                fwg = netC(fake)
                
                loss_G = fwg
                loss_G.backward()
                optimizerG.step()       
            
            if (i+1)%display_interval == 0:
                print('Epoch [{}/{}], Step [{}/{}], critic_loss: {:.4f}, g_loss: {:.4f}, fw(x): {:.4f}, fw(G(z)): {:.4f}' 
                        .format(epoch, epochs, i+1, len(data_loader), loss_fw.item(),  fake_critic.item(), 
                                real_critic.item(), fake_critic.item()))
                Gen_losses.append(fake_critic.item())
                Cri_losses.append(loss_fw.item())
                with torch.no_grad():
                    netG.eval()
                    fake = netG(fixed_noise).detach().cpu()
                    img_list.append(torchvision.utils.make_grid(fake, padding=1, pad_value=1, normalize=True))
                    netG.train()                                                                                     
    
    #  At the end of training, make plots from the data in Gen_losses and Cri_losses:
    plt.figure(figsize=(10,5))                                                                             
    plt.title("Generator and Critic Loss During Training")                                          
    plt.plot(Gen_losses,label="G")                                                                           
    plt.plot(Cri_losses,label="C")                                                                           
    plt.xlabel("iterations")                                                                               
    plt.ylabel("Loss")                                                                                     
    plt.legend()                                                                                           
    plt.savefig(dir_name_for_results + "gen_and_critic_loss_training.png")                                  
    plt.show()                                                                                             
    
    #  Create GIF            
    images = []                                                                                            
    for imgobj in img_list:                                                                                
        img = tvt.ToPILImage()(imgobj)                                                                    
        images.append(img)                                                                                 
    imageio.mimsave(dir_name_for_results + "generation_animation.gif", images, fps=5)                     
    
    # Compare Real and Fake Images
    real_batch = next(iter(data_loader))                                                        
    real_batch = real_batch
    plt.figure(figsize=(15,15))                                                                           
    plt.subplot(1,2,1)                                                                                    
    plt.axis("off")                                                                                       
    plt.title("Real Images")                                                                              
    plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch.to(device), 
                                        padding=1, pad_value=1, normalize=True).cpu(),(1,2,0)))  
    plt.subplot(1,2,2)                                                                             
    plt.axis("off")                                                                                
    plt.title("Fake Images")                                                                       
    plt.imshow(np.transpose(img_list[-1],(1,2,0)))                                                 
    plt.savefig(dir_name_for_results + "real_vs_fake_images.png")                                 
    plt.show()

    # Save model weights
    checkpoint_path_G = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                        f'{model_name}_G.pt')
    torch.save(netG.state_dict(), checkpoint_path_G)
    checkpoint_path_C = os.path.join('/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models', 
                                f'{model_name}_C.pt')
    torch.save(netC.state_dict(), checkpoint_path_C) 

    return Cri_losses, Gen_losses, img_list

# Train a WGAN using Method 2
net3_losses = train_wgan_2(device, netC, netG, data_loader = train_data_loader, 
                        model_name = 'HW7_WGAN_2', dir_name_for_results =
                         '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/wgan/', 
                        epochs=epochs, display_interval = display_interval)

# Validate WGAN with Method 2
save_path = '/content/drive/MyDrive/Purdue/ECE60146/HW7/saved_models/HW7_WGAN_2_G.pt'
validate_gan(device, netG,'/content/drive/MyDrive/Purdue/ECE60146/HW7/data/eval', \
                '/content/drive/MyDrive/Purdue/ECE60146/HW7/data/wgan/images', 
             model_name = 'WGAN', model_path = save_path)