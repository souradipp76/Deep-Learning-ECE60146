# -*- coding: utf-8 -*-
"""hw2_SouradipPal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12_MkHvjiZGw2zP_nPxMbJJJbBNipHOz-
"""

from google.colab import drive
drive.mount('/content/drive')

from PIL import Image, ExifTags
import torch
import torchvision.transforms as tvt
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import wasserstein_distance

# Method to load PIL Image from file 
def load_image(filepath):
    img = Image.open(filepath)
   
    # Image orientation issue resolved as given in 
    # https://stackoverflow.com/questions/13872331
    try:
        for orientation in ExifTags.TAGS.keys():
            if ExifTags.TAGS[orientation]=='Orientation':
                break
        
        exif = img._getexif()
        if exif == None:
            return img

        if exif[orientation] == 3:
            img = img.rotate(180, expand=True)
        elif exif[orientation] == 6:
            img = img.rotate(270, expand=True)
        elif exif[orientation] == 8:
            img = img.rotate(90, expand=True)
        return img

    except (AttributeError, KeyError, IndexError):
        return img

img1 = load_image('/content/drive/MyDrive/Purdue/ECE60146/HW2/data/stop_sign_001.jpg')
img2 = load_image('/content/drive/MyDrive/Purdue/ECE60146/HW2/data/stop_sign_002.jpg')

fig, axes = plt.subplots(1, 2, figsize=(6, 5), sharey=True)
axes[0].imshow(img1)
axes[1].imshow(img2)
plt.show()

transforms = tvt.Compose([tvt.ToTensor(), tvt.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])

img1_transformed = transforms(img1)
img2_transformed = transforms(img2)

# Logic taken from previous year solution 
# https://engineering.purdue.edu/DeepLearn/2_best_solutions/2022/hw2_s22_sol1.pdf
# calculate Wasserstein distance between two images
def calculate_dist(im1, im2, num_bins = 10):
    channels_im1 = [im1[ch] for ch in range(3)]
    channels_im2 = [im2[ch] for ch in range(3)]
    histTensor1 = torch.zeros(3, num_bins, dtype=torch.float)
    histTensor2 = torch.zeros(3, num_bins, dtype=torch.float)
    hists1 = [torch.histc(channels_im1[ch], num_bins, -3.0, 3.0) for ch in range(3)]
    hists1 = [hists1[ch].div(hists1[ch].sum()) for ch in range(3)]
    hists2 = [torch.histc(channels_im2[ch], num_bins, -3.0, 3.0) for ch in range(3)]
    hists2 = [hists2[ch].div(hists2[ch].sum()) for ch in range(3)]

    d = []
    channels = ["R", "G", "B"]
    for ch in range(3):
        histTensor1[ch] = hists1[ch]
        histTensor2[ch] = hists2[ch]
        dist = wasserstein_distance(torch.squeeze(histTensor1[ch]).cpu().numpy(), 
                                    torch.squeeze(histTensor2[ch]).cpu().numpy())
        d.append(dist)
    return d

calculate_dist(img1_transformed, img2_transformed)

# Experimenting Affine transformation using degree, translate, shear parameters
trans = np.linspace(0, 0.4, 5)
shear = np.linspace(-60, 60, 9)
min_affine_d = 1e9

for i, s in enumerate(shear):
    for j, t in enumerate(trans):
        affine_transformer = tvt.RandomAffine(degrees=(-5, 5), translate=(t, t), 
                                              shear = [0, 0, s, s+5])
        img_t = affine_transformer(img1)
        img_t_transformed = transforms(img_t)
        d = calculate_dist(img_t_transformed, img2_transformed)
        # Comparing the L2 norm of Wassertein distance of the three channels
        if np.linalg.norm(d) < min_affine_d:
            min_affine_d = np.linalg.norm(d)
            img_affine = img_t
plt.show()

# Plot Best Image after Affine Transform
fig, axes = plt.subplots(1, 2, figsize=(8, 5), sharey=True)
axes[0].imshow(img2)
axes[0].set_title('Original Oblique Image')
axes[1].imshow(img_affine)
axes[1].set_title('Best Affine Transformed Image')

plt.show()

# Experimenting Projective transformation using distortion parameter
min_pers_d = 1e9

W, H  = img1.size

for i in range(20):
    startpoints, endpoints = tvt.RandomPerspective().get_params(W, H, 0.3)
    img_t = tvt.functional.perspective(img1, startpoints, endpoints)
    img_t_transformed = transforms(img_t)
    d = calculate_dist(img_t_transformed, img2_transformed)
    # Comparing the L2 norm of Wassertein distance of the three channels
    if np.linalg.norm(d) < min_pers_d:
        min_pers_d = np.linalg.norm(d)
        img_perspective = img_t
plt.show()

# Plot Best Image after Projective Transform
fig, axes = plt.subplots(1, 2, figsize=(8, 5), sharey=True)
axes[0].imshow(img2)
axes[0].set_title('Original Oblique Image')
axes[1].imshow(img_perspective)
axes[1].set_title('Best Projective Transformed Image')
plt.show()

print(min_affine_d, min_pers_d)

import os
import torch

# Creating custom dataset class
class MyDataset(torch.utils.data.Dataset):
    def __init__(self, root):
        super().__init__()
        # Obtain meta information (e.g. list of file names )
        # Initialize data augmentation transforms, etc.
        self.root_dir = root
        self.img_paths = os.listdir(self.root_dir)
        self.transforms = tvt.Compose([tvt.ToTensor(), tvt.RandomHorizontalFlip(), 
                                       tvt.RandomResizedCrop(256, scale=(0.9, 1.0)), 
                                       tvt.GaussianBlur(5, sigma=(1.0, 2.0))])

    def __len__(self):
        # Return the total number of images
        return len(self.img_paths)

    def __getitem__(self, index):
        # Read an image at index and perform augmentations
        # Return the tuple : (augmented tensor, integer label)
        index = index % len(self.img_paths)
        img_path = self.img_paths[index]
        path = os.path.join(self.root_dir, img_path)
        im = load_image(path)
        im_transformed = self.transforms(im)
        return im_transformed, index

# Example Output
my_dataset = MyDataset(root = '/content/drive/MyDrive/Purdue/ECE60146/HW2/data/')
print(len(my_dataset))
index = 10
print(my_dataset[index][0].shape , my_dataset[index][1])
index = 50
print(my_dataset[index][0].shape , my_dataset[index][1])

# PLot three original images with augement versions
fig, axes = plt.subplots(3, 2, figsize=(10, 12), sharey=True)
indices = np.random.randint(0, len(my_dataset), 3)
for i in range(3):
    index = indices[i]
    img, label = my_dataset[index]
    img_orig = load_image(os.path.join(my_dataset.root_dir, my_dataset.img_paths[index]))
    img_orig = img_orig.resize((256, 256))
    axes[i][0].imshow(img_orig)
    axes[i][0].set_title('Original Image')
    axes[i][1].imshow(np.array(img).transpose(1,2,0))
    axes[i][1].set_title('Augmented Image')

plt.show()

# Defining dataloader
my_dataloader = torch.utils.data.DataLoader(dataset=my_dataset, batch_size=4, 
                                            shuffle=True, num_workers = 2)

# Get a batch of augmented images and plot it
iterator = iter(my_dataloader)
batch = next(iterator)
fig, axes = plt.subplots(1, 4, figsize=(12, 8), sharey=True)
for i in range(4):
    img = batch[0][i]
    axes[i].imshow(np.array(img).transpose(1,2,0))
plt.show()

import time

# Compare dataset and dataloader performance
def compare_perf(dataset, num_iters = 1000):
    n = len(dataset)
    indices = np.random.randint(n, size = num_iters)
    start = time.time()
    for i in indices:
        img, label = dataset[i]
    end = time.time()
    print(f'Time to process 1000 images in Dataset using __get_item__: {end - start} s')

    for bsize in [2,4,8]:
        for nworkers in [2, 3, 4]:
            print(f'Performance of dataloader with batch size {bsize}, num_workers {nworkers}:')
            dataloader = torch.utils.data.DataLoader(dataset=dataset, 
                                                     batch_size=bsize, 
                                                     shuffle=True, 
                                                     num_workers = nworkers)
            iterator = iter(dataloader)
            start = time.time()
            # multiple iteration of dataloader (https://stackoverflow.com/questions/47714643/)
            for i in range(int(num_iters/bsize)):
                try:
                    img, label = next(iterator)
                except StopIteration:
                    iterator = iter(dataloader)
                    img, label = next(iterator)
            end = time.time()
            print(f'Time to process {num_iters} images in DataLoader: {end - start} s')

compare_perf(my_dataset, num_iters = 1000)